{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SiameseNetwork.ipynb","provenance":[],"mount_file_id":"1kN18aAJIL3bNJbJz6bSj8pszfqWzusXu","authorship_tag":"ABX9TyOBL5C+ylWgHUsLY210mdmz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# This network implements the Siamese Network for object classification on LV data"],"metadata":{"id":"SRMjHKCpxB9t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPt-cHv4SvGe"},"outputs":[],"source":["import numpy as np, glob, time\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision import transforms, models, datasets\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["# This cell and nesxt one install two libraries that we need to run this notebook.\n","# They are just required due to the way we implemented the code and are not necessary\n","# for the Siamese network\n","!pip install torch_snippets"],"metadata":{"id":"PhV2G8IJiIiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install jsonlines"],"metadata":{"id":"CdDIa3bB_vpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This data set makes triplets that first two ielements are images and third is either 1 or 0 \n","# depending if the two images belong to fake category or real \n","from torch_snippets import *\n","\n","class SiameseNetworkDataset(Dataset):\n","    def __init__(self, folder, transform=None, should_invert=True):\n","        self.folder = folder\n","        self.items = Glob(f'{self.folder}/*/*') \n","        self.transform = transform\n","    def __getitem__(self, ix):\n","        itemA = self.items[ix]\n","        auth = fname(parent(itemA))\n","        same_auth = randint(2)\n","        if same_auth:\n","            itemB = choose(Glob(f'{self.folder}/{auth}/*', silent=True))\n","        else:\n","            while True:\n","                itemB = choose(self.items)\n","                if auth != fname(parent(itemB)):\n","                    break\n","        imgA = read(itemA)\n","        imgB = read(itemB)\n","        if self.transform:\n","            imgA = self.transform(imgA)\n","            imgB = self.transform(imgB)\n","        return imgA, imgB, np.array([1-same_auth])\n","    def __len__(self):\n","        return len(self.items)"],"metadata":{"id":"3ngSA3tUTLTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","\n","trn_tfms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Grayscale(),\n","    #transforms.RandomHorizontalFlip(),\n","    #transforms.RandomAffine(5, (0.01,0.2),scale=(0.9,1.1)),\n","    transforms.Resize((256,256)),\n","    transforms.ToTensor(),\n","    transforms.ConvertImageDtype(torch.float),\n","    transforms.Normalize((0.5), (0.5))\n","])\n","\n","val_tfms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Grayscale(),\n","    transforms.Resize((256,256)),\n","    transforms.ToTensor(),\n","    transforms.ConvertImageDtype(torch.float),\n","    transforms.Normalize((0.5), (0.5))\n","])"],"metadata":{"id":"UBrj52wVTiCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# r directories contain real images and f include fake images\n","trn_ds = SiameseNetworkDataset(folder=\"./drive/MyDrive/LV_data/train\", transform=trn_tfms)\n","val_ds = SiameseNetworkDataset(folder=\"./drive/MyDrive/LV_data/val\", transform=val_tfms)\n","\n","trn_dl = DataLoader(trn_ds, shuffle=True, batch_size=64)\n","val_dl = DataLoader(val_ds, shuffle=False, batch_size=64)"],"metadata":{"id":"ReMGuDK4bENm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convBlock(ni, no):\n","    return nn.Sequential(\n","        nn.Dropout(0.2),\n","        nn.Conv2d(ni, no, kernel_size=3, padding=1, padding_mode='reflect'),\n","        nn.ReLU(inplace=True),\n","        nn.BatchNorm2d(no),\n","    )"],"metadata":{"id":"wl-bM6sqiyky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        self.features = nn.Sequential(\n","            convBlock(1,4),\n","            convBlock(4,8),\n","            convBlock(8,8),\n","            nn.Flatten(),\n","            nn.Linear(8*256*256, 500), nn.ReLU(inplace=True),\n","            nn.Linear(500, 500), nn.ReLU(inplace=True),\n","            nn.Linear(500, 10)\n","        )\n","\n","    def forward(self, input1, input2):\n","        output1 = self.features(input1)\n","        output2 = self.features(input2)\n","        return output1, output2"],"metadata":{"id":"CAYnhy6vjOt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#We used this ContrastiveLoss for training but another rather newer loss is implemented in below cell\n","class ContrastiveLoss(torch.nn.Module):\n","    \"\"\"\n","    Contrastive loss function.\n","    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n","    \"\"\"\n","\n","    def __init__(self, margin=2.0):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","    def forward(self, output1, output2, label):\n","        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n","        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n","                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n","        acc = ((euclidean_distance > 0.6) == label).float().mean()\n","        return loss_contrastive, acc"],"metadata":{"id":"UCNwSFJ6jO8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","from torch.nn import Parameter\n","\n","def l2_norm(input,axis=1):\n","    norm = torch.norm(input,2,axis,True)\n","    output = torch.div(input, norm)\n","    return output\n","\n","class Am_softmax(torch.nn.Module):\n","    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n","    def __init__(self,embedding_size=10,classnum=2):\n","        super(Am_softmax, self).__init__()\n","        self.classnum = classnum\n","        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n","        # initial kernel\n","        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n","        self.m = 0.35 # additive margin recommended by the paper\n","        self.s = 30. # see normface https://arxiv.org/abs/1704.06369\n","    def forward(self,embbedings,label):\n","        kernel_norm = l2_norm(self.kernel,axis=0)\n","        cos_theta = torch.mm(embbedings,kernel_norm)\n","        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n","        phi = cos_theta - self.m\n","        label = label.view(-1,1) #size=(B,1)\n","        index = cos_theta.data * 0.0 #size=(B,Classnum)\n","        index.scatter_(1,label.data.view(-1,1),1)\n","        index = index.byte()\n","        output = cos_theta * 1.0\n","        output[index] = phi[index] #only change the correct predicted output\n","        output *= self.s # scale up in order to make softmax work, first introduced in normface\n","        acc = ((cos_theta > 0.9) == label).float().mean()\n","        return output, acc"],"metadata":{"id":"IXJ7KkYu9giq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_batch(model, data, optimizer, criterion):\n","    imgsA, imgsB, labels = [t.to(device) for t in data]\n","    optimizer.zero_grad()\n","    codesA, codesB = model(imgsA, imgsB)\n","    loss, acc = criterion(codesA, codesB, labels)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item(), acc.item()\n","\n","@torch.no_grad()\n","def validate_batch(model, data, criterion):\n","    imgsA, imgsB, labels = [t.to(device) for t in data]\n","    codesA, codesB = model(imgsA, imgsB)\n","    loss, acc = criterion(codesA, codesB, labels)\n","    return loss.item(), acc.item()"],"metadata":{"id":"ZJwNuJWsjPHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SiameseNetwork().to(device)\n","criterion = ContrastiveLoss()\n","#criterion = Am_softmax()\n","optimizer = optim.Adam(model.parameters(),lr = 0.001)"],"metadata":{"id":"REW33koxjbNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import lr_scheduler\n","\n","n_epochs = 500\n","log = Report(n_epochs)\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n","\n","for epoch in range(n_epochs):\n","    N = len(trn_dl)\n","    for i, data in enumerate(trn_dl):\n","        loss, acc = train_batch(model, data, optimizer, criterion)\n","        log.record(epoch+(1+i)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n","    N = len(val_dl)\n","    for i, data in enumerate(val_dl):\n","        loss, acc = validate_batch(model, data, criterion)\n","        log.record(epoch+(1+i)/N, val_loss=loss, val_acc=acc, end='\\r')\n","    if (epoch+1)%50==0: log.report_avgs(epoch+1)\n","    if (epoch+1)%100==0: torch.save(model, '/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese_Amloss.pth')\n","    if (epoch+1)%100==0: scheduler.step()\n","    #if epoch==10: optimizer = optim.Adam(model.parameters(), lr=0.0005)\n"],"metadata":{"id":"tYw9ajvzjbVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TP = 10, FP = 10, TN = 59, FN = 48    sen = 17%  sp = 85%"],"metadata":{"id":"rtmjnkRvY17i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')"],"metadata":{"id":"zoCufxK99_w2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Rebag_model = torch.load('/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')"],"metadata":{"id":"lF3Sa5eEwBwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_epochs = 300\n","log = Report(n_epochs)\n","\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n","\n","for epoch in range(n_epochs):\n","    N = len(trn_dl)\n","    for i, data in enumerate(trn_dl):\n","        loss, acc = train_batch(Rebag_model, data, optimizer, criterion)\n","        log.record(epoch+(1+i)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n","    N = len(val_dl)\n","    for i, data in enumerate(val_dl):\n","        loss, acc = validate_batch(Rebag_model, data, criterion)\n","        log.record(epoch+(1+i)/N, val_loss=loss, val_acc=acc, end='\\r')\n","    if (epoch+1)%50==0: log.report_avgs(epoch+1)\n","    if (epoch+1)%100==0: torch.save(model, '/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')\n","    if (epoch+1)%100==0: scheduler.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjtguSFVgC8L","executionInfo":{"status":"ok","timestamp":1646007172390,"user_tz":300,"elapsed":2237624,"user":{"displayName":"Reza hojjaty saeedy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18162372094943119950"}},"outputId":"6cf63e2a-b537-4a9e-fcb3-6829ad0321fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 50.000\ttrn_loss: 0.041\ttrn_acc: 0.973\tval_loss: 1.240\tval_acc: 0.583\t(372.29s - 1861.47s remaining)\n","EPOCH: 100.000\ttrn_loss: 0.099\ttrn_acc: 0.873\tval_loss: 1.323\tval_acc: 0.437\t(743.08s - 1486.16s remaining)\n","EPOCH: 150.000\ttrn_loss: 0.125\ttrn_acc: 0.899\tval_loss: 1.257\tval_acc: 0.611\t(1119.37s - 1119.37s remaining)\n","EPOCH: 200.000\ttrn_loss: 0.083\ttrn_acc: 0.953\tval_loss: 1.402\tval_acc: 0.516\t(1487.80s - 743.90s remaining)\n","EPOCH: 250.000\ttrn_loss: 0.074\ttrn_acc: 0.919\tval_loss: 1.244\tval_acc: 0.539\t(1862.93s - 372.59s remaining)\n","EPOCH: 300.000\ttrn_loss: 0.103\ttrn_acc: 0.907\tval_loss: 1.291\tval_acc: 0.543\t(2232.61s - 0.00s remaining)\n"]}]},{"cell_type":"code","source":["#TP = 17, FP = 17, TN = 51, FN = 42  sen = 28%  sp = 75%"],"metadata":{"id":"PzKmd5ojZLCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Rebag_model800 = torch.load('/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')"],"metadata":{"id":"cfOCXiwN3xEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_epochs = 700\n","log = Report(n_epochs)\n","\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n","\n","for epoch in range(n_epochs):\n","    N = len(trn_dl)\n","    for i, data in enumerate(trn_dl):\n","        loss, acc = train_batch(Rebag_model800, data, optimizer, criterion)\n","        log.record(epoch+(1+i)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n","    N = len(val_dl)\n","    for i, data in enumerate(val_dl):\n","        loss, acc = validate_batch(Rebag_model800, data, criterion)\n","        log.record(epoch+(1+i)/N, val_loss=loss, val_acc=acc, end='\\r')\n","    if (epoch+1)%50==0: log.report_avgs(epoch+1)\n","    if (epoch+1)%100==0: torch.save(model, '/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')\n","    if (epoch+1)%100==0: scheduler.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_I_a5kBb33DT","executionInfo":{"status":"ok","timestamp":1646015971648,"user_tz":300,"elapsed":5255636,"user":{"displayName":"Reza hojjaty saeedy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18162372094943119950"}},"outputId":"602f1ac2-c5f6-4cc2-9970-71a4a8695c73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 50.000\ttrn_loss: 0.063\ttrn_acc: 0.949\tval_loss: 1.289\tval_acc: 0.484\t(370.66s - 4818.57s remaining)\n","EPOCH: 100.000\ttrn_loss: 0.054\ttrn_acc: 0.965\tval_loss: 1.209\tval_acc: 0.500\t(738.30s - 4429.83s remaining)\n","EPOCH: 150.000\ttrn_loss: 0.072\ttrn_acc: 0.941\tval_loss: 1.135\tval_acc: 0.575\t(1115.36s - 4089.64s remaining)\n","EPOCH: 200.000\ttrn_loss: 0.129\ttrn_acc: 0.849\tval_loss: 1.194\tval_acc: 0.497\t(1484.26s - 3710.65s remaining)\n","EPOCH: 250.000\ttrn_loss: 0.071\ttrn_acc: 0.945\tval_loss: 1.208\tval_acc: 0.500\t(1868.93s - 3364.07s remaining)\n","EPOCH: 300.000\ttrn_loss: 0.175\ttrn_acc: 0.934\tval_loss: 1.144\tval_acc: 0.484\t(2240.48s - 2987.30s remaining)\n","EPOCH: 350.000\ttrn_loss: 0.059\ttrn_acc: 0.957\tval_loss: 1.186\tval_acc: 0.528\t(2615.06s - 2615.06s remaining)\n","EPOCH: 400.000\ttrn_loss: 0.169\ttrn_acc: 0.899\tval_loss: 1.340\tval_acc: 0.473\t(2987.25s - 2240.44s remaining)\n","EPOCH: 450.000\ttrn_loss: 0.154\ttrn_acc: 0.857\tval_loss: 1.232\tval_acc: 0.516\t(3370.10s - 1872.28s remaining)\n","EPOCH: 500.000\ttrn_loss: 0.111\ttrn_acc: 0.888\tval_loss: 1.404\tval_acc: 0.457\t(3738.92s - 1495.57s remaining)\n","EPOCH: 550.000\ttrn_loss: 0.083\ttrn_acc: 0.930\tval_loss: 1.188\tval_acc: 0.556\t(4121.27s - 1123.98s remaining)\n","EPOCH: 600.000\ttrn_loss: 0.104\ttrn_acc: 0.907\tval_loss: 1.758\tval_acc: 0.243\t(4496.88s - 749.48s remaining)\n","EPOCH: 650.000\ttrn_loss: 0.074\ttrn_acc: 0.957\tval_loss: 1.204\tval_acc: 0.622\t(4878.04s - 375.23s remaining)\n","EPOCH: 700.000\ttrn_loss: 0.071\ttrn_acc: 0.945\tval_loss: 1.417\tval_acc: 0.469\t(5250.26s - 0.00s remaining)\n"]}]},{"cell_type":"code","source":["test_ds = SiameseNetworkDataset(folder=\"./drive/MyDrive/LV_data/test\", transform=val_tfms)\n","\n","test_dl = DataLoader(test_ds, shuffle=False, batch_size=1)"],"metadata":{"id":"itESQ9ilkcey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Rebag_model1500 = torch.load('/content/drive/MyDrive/Rebag_Siamese/Rebag_Siamese.pth')"],"metadata":{"id":"BQxwGg4P2P7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataiter = iter(test_dl)\n","labels = []\n","preds = []\n","\n","for i in range(len(test_dl)):\n","    imgA, imgB, label = next(dataiter)\n","    imgA, imgB, label = imgA.to(device), imgB.to(device), label.to(device)\n","    outA, outB = Rebag_model1500(imgA, imgB)\n","    euclidean_distance = F.pairwise_distance(outA, outB, keepdim = True)\n","    pred = (euclidean_distance > 0.6).float()\n","    preds.append(pred.item()), labels.append(label.item())\n"],"metadata":{"id":"2Vmrqi2Wl69f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idh0esVEXsck","executionInfo":{"status":"ok","timestamp":1645851983206,"user_tz":300,"elapsed":311,"user":{"displayName":"Reza hojjaty saeedy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18162372094943119950"}},"outputId":"9760d433-b185-4a12-aa09-9307c40ac6a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1]], device='cuda:0')"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["def confusion(prediction, truth):\n","    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n","    tensors, i.e. the amount of positions where the values of `prediction`\n","    and `truth` are\n","    - 1 and 1 (True Positive)\n","    - 1 and 0 (False Positive)\n","    - 0 and 0 (True Negative)\n","    - 0 and 1 (False Negative)\n","    \"\"\"\n","\n","    confusion_vector = prediction / truth\n","    # Element-wise division of the 2 tensors returns a new tensor which holds a\n","    # unique value for each case:\n","    #   1     where prediction and truth are 1 (True Positive)\n","    #   inf   where prediction is 1 and truth is 0 (False Positive)\n","    #   nan   where prediction and truth are 0 (True Negative)\n","    #   0     where prediction is 0 and truth is 1 (False Negative)\n","\n","    true_positives = torch.sum(confusion_vector == 1).item()\n","    false_positives = torch.sum(confusion_vector == float('inf')).item()\n","    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n","    false_negatives = torch.sum(confusion_vector == 0).item()\n","\n","    return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"TZ7YUHAzBkMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion(torch.Tensor(preds), torch.Tensor(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yHJIzPfW78Y","executionInfo":{"status":"ok","timestamp":1646016032626,"user_tz":300,"elapsed":151,"user":{"displayName":"Reza hojjaty saeedy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18162372094943119950"}},"outputId":"7aad369d-45e9-42fe-9c96-a8748db36bc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 8, 57, 52)"]},"metadata":{},"execution_count":31}]}]}